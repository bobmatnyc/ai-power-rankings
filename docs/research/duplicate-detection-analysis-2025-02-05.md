# Duplicate Article Detection Analysis

**Date:** 2025-02-05
**Status:** Investigation Complete
**Problem:** 5 articles about Apple Xcode agentic coding were ingested from different sources (CNBC, TechCrunch, Apple Newsroom, etc.) when they should have been detected as duplicates.

---

## Executive Summary

The current duplicate detection system **only checks for exact URL matches**. Articles covering the same story from different publishers have different URLs, so they are never flagged as duplicates. This is why 5 articles about Apple's Xcode agentic coding announcement were all ingested separately.

---

## Current Deduplication Approach

### Location: `lib/services/automated-ingestion.service.ts`

**Method:** `checkDuplicates(urls: string[]): Promise<Set<string>>`

**How it works:**
1. Takes an array of URLs from search results
2. Queries the `articles` table for matching `sourceUrl` values
3. Returns a Set of URLs that already exist in the database
4. Articles with matching URLs are skipped

**Code (lines 544-573):**
```typescript
async checkDuplicates(urls: string[]): Promise<Set<string>> {
  const db = getDb();
  // ...
  const existingArticles = await db
    .select({ sourceUrl: articles.sourceUrl })
    .from(articles)
    .where(inArray(articles.sourceUrl, urls));

  const existingUrls = new Set(
    existingArticles
      .map((a) => a.sourceUrl)
      .filter((url): url is string => url !== null)
  );
  return existingUrls;
}
```

### When Check is Performed

The duplicate check occurs in **Step 3** of `runDailyDiscovery()` (lines 272-280):

```typescript
// Step 3: Filter duplicates
const urls = searchResults.map((r) => r.url);
const existingUrls = await this.checkDuplicates(urls);
const newArticles = searchResults.filter((r) => !existingUrls.has(r.url));
```

### What Happens to Duplicates

- Duplicates are counted in `articlesSkipped`
- They are logged with `[AutomatedIngestion] Filtered duplicates`
- They are simply filtered out of the ingestion pipeline
- No semantic analysis or title comparison is performed

---

## Why Semantic Duplicates Aren't Caught

### Root Cause

The system performs **URL-based deduplication only**. There is:
- **No title similarity checking**
- **No content similarity/embedding comparison**
- **No topic/story clustering**
- **No entity extraction to detect same-topic articles**

### Example of the Problem

Five articles about "Apple Xcode agentic coding" from:
- CNBC: `https://cnbc.com/article/apple-xcode-ai...`
- TechCrunch: `https://techcrunch.com/2025/01/apple-xcode...`
- Apple Newsroom: `https://apple.com/newsroom/xcode-agent...`
- The Verge: `https://theverge.com/apple-xcode-agent...`
- Ars Technica: `https://arstechnica.com/gadgets/apple-xcode...`

Each has a unique URL, so **none are detected as duplicates**, despite covering the identical story.

### Search Service Deduplication

Both `brave-search.service.ts` (line 95-110) and `tavily-search.service.ts` (line 121-136) have **within-session URL deduplication** to prevent the same URL appearing twice in search results, but this does not help with cross-source semantic duplicates.

---

## Summary Generation

### Location: `lib/services/article-ingestion.service.ts`

**Class:** `AIAnalyzer`
**Method:** `analyzeContent()` (lines 495-720)

### LLM Prompts for Summary Generation

The summary is generated by the LLM with these specifications (from the system prompt, lines 506-532):

```
6. Creating COMPREHENSIVE content:
   - Summary: **750-1000 words** - This is the MAIN content readers will see
   - Rewritten content: Approximately 1500 words (7500-9000 characters) - Optional extended version
```

### Current Length Constraints

| Field | Target Length | Purpose |
|-------|---------------|---------|
| `summary` | 750-1000 words | Main article content shown to readers |
| `rewritten_content` | ~1500 words (7500-9000 chars) | Optional extended version for archival |
| Input content | Max 15,000 chars | Truncated from source for LLM processing |
| max_tokens | 32,000 | LLM output token limit |

---

## Specific Code Locations for Implementing Fixes

### 1. Add Semantic Duplicate Detection

**File:** `lib/services/automated-ingestion.service.ts`

**Location:** Between steps 3 and 4 (after line 303)

**Suggested approach:** Add a new method `checkSemanticDuplicates()` that:
- Takes new article titles/descriptions
- Compares against recent articles (last 7 days) using embeddings or LLM
- Returns articles that are semantically similar

### 2. Title Similarity Check

**File:** `lib/services/automated-ingestion.service.ts`

**Location:** Inside or after `checkDuplicates()` method (line 544)

**Suggested approach:** Add title-based deduplication:
- Normalize titles (lowercase, remove punctuation)
- Use fuzzy string matching (Levenshtein distance, Jaccard similarity)
- Flag articles with >80% title similarity

### 3. Enhanced Quality Assessment for Duplicates

**File:** `lib/services/article-quality.service.ts`

**Location:** `buildUserPrompt()` method (line 167)

**Suggested approach:** Pass recent article titles to the quality assessment LLM and ask:
- "Does this article cover the same story as any of these recent articles?"
- Return `shouldIngest: false` if it's a semantic duplicate

### 4. Summary Length Validation

**File:** `lib/services/article-ingestion.service.ts`

**Location:** After LLM response parsing (around line 691)

**Suggested approach:** Add validation to ensure summaries meet length requirements:
- Check word count is within 750-1000 words
- Regenerate if too short
- Truncate gracefully if too long

---

## Recommendations

### Short-Term Fix (Low Effort)

1. **Title similarity check** before quality assessment
   - Compare normalized titles using string similarity
   - Skip articles with >80% title similarity to recent ingested articles
   - Implementation: ~50 lines of code

### Medium-Term Fix (Medium Effort)

2. **LLM-based duplicate detection** in quality assessment
   - Enhance `ArticleQualityService` to check for topic overlap
   - Pass recent article titles/summaries to the quality LLM
   - Ask LLM to identify if article covers same story
   - Implementation: ~100 lines of code + prompt changes

### Long-Term Fix (Higher Effort)

3. **Embedding-based semantic clustering**
   - Generate embeddings for article titles/summaries
   - Store embeddings in vector database
   - Query for similar articles before ingestion
   - Cluster related articles into "story groups"
   - Implementation: Requires embedding service + vector storage

---

## Files Referenced

| File | Lines | Purpose |
|------|-------|---------|
| `lib/services/automated-ingestion.service.ts` | 272-280, 544-573 | Duplicate detection logic |
| `lib/services/article-ingestion.service.ts` | 506-532, 586-597 | Summary generation prompts |
| `lib/services/article-quality.service.ts` | 78-133 | Quality assessment (potential duplicate check location) |
| `lib/services/brave-search.service.ts` | 95-110 | Search result deduplication |
| `lib/services/tavily-search.service.ts` | 121-136 | Search result deduplication |

---

## Next Steps

1. Choose implementation approach based on priority and effort
2. Implement title similarity as quick win
3. Consider embedding-based approach for production-grade solution
4. Add monitoring for duplicate detection effectiveness
